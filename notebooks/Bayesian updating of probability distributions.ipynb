{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As I\u2019ve started learning more about Bayesian statistical methods the biggest light bulb moment for me was when I started thinking in terms of distributions. I was raised on the notion of single number answers. Because of that, I thought I had mastered Bayesian methods when I could recite P(A|B) = P(B|A) P(A) / P(B). WRONG.\n",
      "\n",
      "Today\u2019s algorithm will show a simple example of how to deal with probabilities as distributions. There are two key concepts: updating our distribution with data, and normalizing the distribution.\n",
      "\n",
      "First allow me to introduce today\u2019s concrete example: Flipping a coin!\n",
      "\n",
      "## Chance of Heads\n",
      "\n",
      "If you flip a coin and it comes up tails 3 times out of 4 how likely is it your coin is actually a fair coin? Let\u2019s say fair means 45-55% of the time it comes up heads.\n",
      "\n",
      "The chance it could come up heads could be anything between 0%-100% right? 0% would mean it\u2019s completely unfair and somehow NEVER comes up heads. 100% would be precisely the opposite. We\u2019re hoping for somewhere in the middle.\n",
      "\n",
      "Now before we\u2019ve flipped the coin we need to decide what the probabilities of our hypotheses between 0% and 100% are. To keep it simple we\u2019re going to assume that each hypothesis is equally likely. This is known as a \u201cuniform distribution.\u201d In python that looks like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "possibilities = [1.0]*101"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we need to normalize this so it represents probabilities. For that, I wrote this function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalize(possibilities):\n",
      "  possibility_sum = sum(possibilities)\n",
      "  for hypothesis in xrange(0,101):\n",
      "    possibility = possibilities[hypothesis]\n",
      "    possibilities[hypothesis] = possibility/possibility_sum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Basically this just makes sure all of the likelihoods for our hypotheses add up to 100% like good little probabilities.\n",
      "\n",
      "This is what this uniform distribution looks like visually:<br />\n",
      "<img src=\"/theme/images/uninformative_prior.png\" />"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Updating with new information\n",
      "So now we flip our coin and let\u2019s say we get heads. Let\u2019s think through what we expect to happen to that uniform distribution above. Starting from 0% and working right\u2026\n",
      "\n",
      "0% Now that we\u2019ve gotten heads once we know that it\u2019s impossible to never get heads. This goes to zero.\n",
      "\n",
      "1% The chances seem very low that if there\u2019s only a 1% chance of getting heads that it\u2019d be the first we\u2019d run into.\n",
      "\n",
      "50% Completely possible. We\u2019ve only flipped once so we can\u2019t have 50% probability. This should be somewhere in the middle.\n",
      "\n",
      "100% Well, we\u2019ve only flipped heads once so we can\u2019t say this is certain but we also can\u2019t rule this out.\n",
      "\n",
      "So how do we update our data in python?\n",
      "\n",
      "We use this function when we flip heads:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def update_success(possibilities):\n",
      "  for hypothesis in xrange(0, 101):\n",
      "    likelihood = possibilities[hypothesis]\n",
      "    possibilities[hypothesis] = likelihood * hypothesis/100.0\n",
      "  normalize(possibilities)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And this function when we flip tails:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def update_failure(possibilities):\n",
      "  for hypothesis in xrange(0, 101):\n",
      "    likelihood = possibilities[hypothesis]\n",
      "    possibilities[hypothesis] = likelihood*(1.0-hypothesis/100.0)\n",
      "  normalize(possibilities)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "They are different in one subtle way. Look closely at the fourth line of each function.\n",
      "\n",
      "On the success function we are multiplying the likelihood by each hypothesized probability of us getting heads. Once we\u2019ve done that for every hypothesis we normalize to get back to a percentage. The failure function multiplies the likelihood of each hypothesis by the probability of the hypothesis being false (according to the hypothesis).\n",
      "\n",
      "This leaves us with the following histogram of likelihoods for each hypothesis: "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"/theme/images/first_success.png\" />"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That\u2019s all of the moving parts. Let\u2019s walk through some more examples so you can convince yourself this works.\n",
      "\n",
      "## Baby stepping through our scenario\n",
      "Next let\u2019s say we flip tails and think through what we expect to see. We\u2019ve already ruled out 0% chance of seeing heads and now we can rule out 100% chance of seeing heads. We do now have one of each though, so I expect the middle of the distribution to swell a bit. Whether it\u2019s a triangle shape or a curve, I\u2019m not sure but something like that.\n",
      "\n",
      "Here\u2019s that distribution: "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"/theme/images/success_failure.png\" />"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It\u2019s curved! Of course! Well\u2026 It\u2019s not really obvious, but it does seem rational at least.\n",
      "\n",
      "Now let\u2019s say we flip two more times and they\u2019re both heads: "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"/theme/images/multiple successes with failure.png\" />"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Getting to an answer\n",
      "Let\u2019s stop here and answer the question I initially asked. How likely is this coin to have a ~50% chance of flipping heads (where that really means 45%-55% chance since statistics is an inexact science)? Here\u2019s how we can approximate the answer. From the histogram we have, we just need to add up the probability from each hypothesis.\n",
      "\n",
      "45% 0.68%\n",
      "46% 0.73%\n",
      "47% 0.78%\n",
      "48% 0.83%\n",
      "49% 0.88%\n",
      "50% 0.94%\n",
      "51% 0.99%\n",
      "52% 1.05%\n",
      "53% 1.11%\n",
      "54% 1.17%\n",
      "55% 1.24%\n",
      "Adding them all up equals a 10% chance.\n",
      "\n",
      "Notice how each individual hypothesis has a really low likelihood? It being exactly 50% is only a .94% chance! What\u2019s that about?\n",
      "\n",
      "This is actually a really cool aspect of this method. You see anytime you deal with probabilities (even in frequentist statistics) you need to deal with ranges of likelihoods. Call them a confidence interval, credibility interval, highest density interval, etc. It\u2019s the same concept.\n",
      "\n",
      "Also, this whole idea of treating individual probabilities as hypotheses was life altering for me. This concept applies generally to anything where you want to evaluate likelihoods. The y-axis will always be probabilities but the x-axis can be any numerical value. Be it money, time, or what have you.\n",
      "\n",
      "Actually since I\u2019ve mentioned credibility intervals, let\u2019s get that from this data as well."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Credibility interval\n",
      "The simplest way to explain a credibility interval is to say it\u2019s essentially a confidence interval that you can easily get from a histogram. It entails saying which hypotheses encompass 95% of the likelihoods you have.\n",
      "\n",
      "I\u2019m running short on time so we\u2019ll just estimate it. I\u2019ve grabbed the data from the program and put it in a spreadsheet. My next step is to sort the data by its likelihoods in descending order and grab the first N values that add up to 95%. Then I need to find the minimum hypothesis in that range and the maximum.\n",
      "\n",
      "I\u2019ve done that for our experiment. 95% of the likelihood falls between 42%-98%. We can interpret this to mean we can\u2019t eliminate the possibility that our coin may still come up heads 50% of the time\u2026 but then we also have some confidence our coin will come up heads greater than 90% of the time. Really this interval is so wide, it really should be interpreted to mean that we need more data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Wrap it up\n",
      "That\u2019s the algorithm. It\u2019s extremely straight forward, but those ~12 lines of code took me a while to truly understand. If you want to learn more I suggest reading about the binomial distribution. I think you might see some similarities between that and what we did. Read more here.\n",
      "\n",
      "Also here\u2019s my full code file in case you want to dive into the code to understand this deeper:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalize(possibilities):\n",
      "  possibility_sum = sum(possibilities)\n",
      "  for hypothesis in xrange(0,101):\n",
      "    possibility = possibilities[hypothesis]\n",
      "    possibilities[hypothesis] = possibility/possibility_sum\n",
      "\n",
      "def update_success(possibilities):\n",
      "  for hypothesis in xrange(0, 101):\n",
      "    likelihood = possibilities[hypothesis]\n",
      "    possibilities[hypothesis] = likelihood*hypothesis/100.0\n",
      "  normalize(possibilities)\n",
      "\n",
      "def update_failure(possibilities):\n",
      "  for hypothesis in xrange(0, 101):\n",
      "    likelihood = possibilities[hypothesis]\n",
      "    possibilities[hypothesis] = likelihood*(1.0-hypothesis/100.0)\n",
      "  normalize(possibilities)\n",
      "\n",
      "# set every possibility to be equally possible\n",
      "possibilities = [1.0]*101\n",
      "\n",
      "# Coin flip, probability of heads\n",
      "normalize(possibilities)\n",
      "update_success(possibilities)\n",
      "update_failure(possibilities)\n",
      "update_success(possibilities)\n",
      "update_success(possibilities)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    }
   ],
   "metadata": {}
  }
 ]
}